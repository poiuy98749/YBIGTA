{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN_pVd5cU2QQ"
      },
      "source": [
        "# 과제: MNIST 데이터를 나만의 NN model로 95 % 이상의 성능으로 training 시켜보자!\n",
        "\n",
        "\n",
        "## Loading MNIST training data\n",
        "\n",
        "출처: 19기 DS 정은서님"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hwZNV5MFU2QQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import BatchNormalization\n",
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Loading the data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scaling(image data는 min-max scaling 주로 사용)\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDU8J2xRU2QQ"
      },
      "source": [
        "## Training Data\n",
        "28 * 28 pixel 값을 가진 총 60000개의 이미지 데이터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jVvXmjQSU2QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37de8ff3-27cd-4f9e-ee34-8e0040a76a2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VTAAYKSU2QQ"
      },
      "source": [
        "Neural network 모델에 맞게 이미지 데이터를 벡터 형태로 데이터를 reshape 합니다.  \n",
        "(Model을 만들 때 *keras.layers.Flatten(input_shape=(28, 28)) 이용해도 됨)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dq36yUX8U2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff68e2d3-ddba-454e-f148-d8881c3124b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) (60000, 10)\n",
            "(10000, 28, 28, 1) (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "# X_train과 X_test를 reshape해서 (Data_size, W, H, C) 형태로 변환\n",
        "X_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "NC = 10   # Number of classes\n",
        "Y_train = np_utils.to_categorical(y_train, NC)\n",
        "Y_test = np_utils.to_categorical(y_test, NC)\n",
        "\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zrQLH9iXU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f0f166d5-e220-41a5-d827-53c942ec7be8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Hint: x_train[0].reshape()\n",
        "plt.imshow(x_train[0]).set_cmap('gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YZXzr-AU2QR"
      },
      "source": [
        "## Training Labels\n",
        "이미지 데이터가 나타내는 숫자값을 label로 가지고 있고, 0부터 9까지의 값을 나타냄  \n",
        "마찬가지로, 60000개의 label이 존재"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "V-JVvQcJU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d487df-92a7-4075-f8ad-2a6526b789c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PgAkJK6yU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de0b0e1-2486-4087-e770-10dad3fe36cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# show MNIST label for above data\n",
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaI3Kv_GU2QR"
      },
      "source": [
        "## 나만의 모델을 tensorflow keras API 를 이용해 만들어 봅시다~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSshVnt2U2QS"
      },
      "source": [
        "* parameters for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "coUZ53nKU2QS"
      },
      "outputs": [],
      "source": [
        "#### 자유롭게 Model을 만들고 compile 해봅시다 ####\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), input_shape = (28, 28, 1)),\n",
        "    keras.layers.Activation('relu'),\n",
        "    BatchNormalization(axis=-1),\n",
        "    keras.layers.Conv2D(32, (3, 3)),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "\n",
        "    BatchNormalization(axis=-1),\n",
        "    keras.layers.Conv2D(64, (3, 3)),\n",
        "    keras.layers.Activation('relu'),\n",
        "    BatchNormalization(axis=-1),\n",
        "    keras.layers.Conv2D(64, (3, 3)),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    keras.layers.Dense(512),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(10),\n",
        "\n",
        "    keras.layers.Activation('softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MLkATHCH6-CJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVhLJHJ9U2QT"
      },
      "source": [
        "내가 만든 모델을 확인해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "GChgw-8sU2QT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7249002f-4cae-41a2-f687-72066d2ef7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_17 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 26, 26, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 12, 12, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 12, 12, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 10, 10, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 10, 10, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 1024)             4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 601,578\n",
            "Trainable params: 598,250\n",
            "Non-trainable params: 3,328\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9zWRRHIU2QT"
      },
      "source": [
        "model을 자유롭게 train 해봅시다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "6uygJ19gU2QT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23cc4c6-57e1-4522-a688-5b43e1b7c07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0157 - accuracy: 0.9950\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0137 - accuracy: 0.9957\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0153 - accuracy: 0.9948\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0098 - accuracy: 0.9966\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0107 - accuracy: 0.9962\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0090 - accuracy: 0.9969\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0098 - accuracy: 0.9967\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0061 - accuracy: 0.9977\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0061 - accuracy: 0.9978\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0065 - accuracy: 0.9979\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7326e84350>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, batch_size = 128, epochs = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8A4zKnEU2QT"
      },
      "source": [
        "95%이상의 성능을 가진 모델을 만들면 완성!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9Xz0qGifU2QU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6b7f57-1302-4fd6-8aaa-334e584bdc4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0277 - accuracy: 0.9924 - 863ms/epoch - 3ms/step\n",
            "\n",
            "Accuracy: 0.9923999905586243\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,Y_test, verbose=2)\n",
        "\n",
        "print('\\nAccuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "EbcuzK_PU2QU"
      },
      "source": [
        "![](https://www.tensorflow.org/versions/master/images/mnist_tensorboard.png)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL(MLP)_과제.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "aceed844c4bf32d438bbd40164f2bae252164e6bce8e3249555949f9c2e6bdc3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}